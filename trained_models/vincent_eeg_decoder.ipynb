{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from scipy.signal import butter, filtfilt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader as DL\n",
    "from torch.utils.data import TensorDataset as TData\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import pickle\n",
    "import braindecode as bd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380 380\n"
     ]
    }
   ],
   "source": [
    "def getAllPickles(directory=\"LHNT EEG\"):\n",
    "    \"\"\"\n",
    "    Searches through the directory and all its subfolders,\n",
    "    returning a list of all .pkl file paths.\n",
    "    \"\"\"\n",
    "    folders = [\n",
    "        drctry for drctry in os.listdir(directory)\n",
    "        if os.path.isdir(os.path.join(directory, drctry))\n",
    "    ]\n",
    "    files = []\n",
    "    for folder in folders:\n",
    "        folder_files = os.listdir(os.path.join(directory, folder))\n",
    "        for file in folder_files:\n",
    "            if \".pkl\" in file:\n",
    "                files.append(os.path.join(directory, folder, file))\n",
    "    return files\n",
    "\n",
    "def npFromPickle(pickle_files):\n",
    "    \"\"\"\n",
    "    Loads NumPy arrays and labels from a list of pickle files.\n",
    "    Label: 0 for 'left', 1 for 'right'.\n",
    "    \"\"\"\n",
    "    np_data = []\n",
    "    labels = []  # 0 is left, 1 is right\n",
    "    for file in pickle_files:\n",
    "        with open(file, \"rb\") as f:\n",
    "            data1 = pickle.load(f)\n",
    "            np_data.append(data1[0])\n",
    "        # infer label from filename\n",
    "        if 'right' in file.split('/')[-1]:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    return np_data, labels\n",
    "\n",
    "np_data, labels = npFromPickle(getAllPickles())\n",
    "print(len(np_data), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_filter(signal, crit_freq=[1, 40], sampling_freq=125, plot=False, channel=0):\n",
    "    \"\"\"\n",
    "    Butterworth bandpass filter. \n",
    "    \"\"\"\n",
    "    order = 4\n",
    "    b, a = scipy.signal.butter(\n",
    "        order, crit_freq, btype='bandpass', fs=sampling_freq\n",
    "    )\n",
    "    processed_signal = scipy.signal.filtfilt(b, a, signal, axis=1)\n",
    "\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel(f'Normalized amplitude of channel {channel}')\n",
    "        plt.title(f'{crit_freq[0]}-{crit_freq[1]}Hz bandpass filter')\n",
    "\n",
    "        # Plot unfiltered\n",
    "        signal_min = np.min(signal, axis=1, keepdims=True)\n",
    "        signal_max = np.max(signal, axis=1, keepdims=True)\n",
    "        normed_signal = (signal - signal_min) / (signal_max - signal_min)\n",
    "\n",
    "        # Plot filtered\n",
    "        filtered_min = np.min(processed_signal, axis=1, keepdims=True)\n",
    "        filtered_max = np.max(processed_signal, axis=1, keepdims=True)\n",
    "        normed_filt = (processed_signal - filtered_min) / (filtered_max - filtered_min)\n",
    "\n",
    "        plt.plot(normed_signal[channel], label='Input')\n",
    "        plt.plot(normed_filt[channel], label='Transformed')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return processed_signal\n",
    "\n",
    "def channel_rearrangment(sig, channel_order):\n",
    "    \"\"\"\n",
    "    Rearranges channels according to the given channel_order list.\n",
    "    NOTE: Channels in channel_order are assumed to be 1-indexed,\n",
    "          so we shift by 1 to make them 0-indexed.\n",
    "    \"\"\"\n",
    "    channel_order = [ch - 1 for ch in channel_order]\n",
    "    reindexed = np.zeros_like(sig)\n",
    "    for i, ind in enumerate(channel_order):\n",
    "        reindexed[i] = sig[ind]\n",
    "    return reindexed\n",
    "  \n",
    "ordered_channels = [1, 9, 11, 3, 2, 12, 10, 4, 13, 5, 15, 7, 14, 16, 6, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = tts(np_data, labels, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_length = 1750\n",
    "\n",
    "def fix_length(sig, fixed_len=875):\n",
    "    \"\"\"\n",
    "    Ensure each EEG signal has exactly fixed_len timepoints.\n",
    "    - If sig is longer than fixed_len, crop it.\n",
    "    - If sig is shorter than fixed_len, zero-pad it.\n",
    "    \"\"\"\n",
    "    c, l = sig.shape  # c = number of channels, l = number of timepoints\n",
    "    if l > fixed_len:\n",
    "        # Crop if it's too long\n",
    "        return sig[:, :fixed_len]\n",
    "    elif l < fixed_len:\n",
    "        # Zero-pad if it's too short\n",
    "        pad_width = fixed_len - l\n",
    "        padded = np.zeros((c, fixed_len))\n",
    "        padded[:, :l] = sig\n",
    "        return padded\n",
    "    else:\n",
    "        # Exactly fixed_len\n",
    "        return sig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eeg = []\n",
    "train_labels = []\n",
    "test_eeg = []\n",
    "test_labels = []\n",
    "\n",
    "for sig, label in zip(train_x, train_y):\n",
    "    # Exclude empty signals\n",
    "    if sig.shape[1] == 0:\n",
    "        continue\n",
    "    # 1) Channel re-index\n",
    "    reindexed_signal = channel_rearrangment(sig, ordered_channels)\n",
    "    # 2) Filter\n",
    "    filtered_sig = bandpass_filter(reindexed_signal, [5, 40], 125)\n",
    "    # 3) Standard scaling\n",
    "    normed_sig = (filtered_sig - np.mean(filtered_sig, axis=1, keepdims=True)) / \\\n",
    "                 np.std(filtered_sig, axis=1, keepdims=True)\n",
    "    if np.isnan(normed_sig).any():\n",
    "        continue\n",
    "\n",
    "    # Crop or pad to 875 timepoints\n",
    "    fixed_sig = fix_length(normed_sig, fixed_len=1750)\n",
    "\n",
    "    train_eeg.append(fixed_sig)\n",
    "    train_labels.append(label)\n",
    "\n",
    "for sig, label in zip(test_x, test_y):\n",
    "    if sig.shape[1] == 0:\n",
    "        continue\n",
    "    reindexed_signal = channel_rearrangment(sig, ordered_channels)\n",
    "    filtered_sig = bandpass_filter(reindexed_signal, [5, 40], 125)\n",
    "    normed_sig = (filtered_sig - np.mean(filtered_sig, axis=1, keepdims=True)) / \\\n",
    "                 np.std(filtered_sig, axis=1, keepdims=True)\n",
    "    if np.isnan(normed_sig).any():\n",
    "        continue\n",
    "\n",
    "    fixed_sig = fix_length(normed_sig, fixed_len=1750)\n",
    "\n",
    "    test_eeg.append(fixed_sig)\n",
    "    test_labels.append(label)\n",
    "\n",
    "import torch\n",
    "\n",
    "# Dimensions: (num_samples, num_channels, num_timepoints)\n",
    "train_eeg_tensor = torch.zeros(\n",
    "    (len(train_eeg), train_eeg[0].shape[0], train_eeg[0].shape[1])\n",
    ")\n",
    "test_eeg_tensor = torch.zeros(\n",
    "    (len(test_eeg), test_eeg[0].shape[0], test_eeg[0].shape[1])\n",
    ")\n",
    "\n",
    "for i in range(len(train_eeg)):\n",
    "    train_eeg_tensor[i] = torch.from_numpy(train_eeg[i].copy())\n",
    "\n",
    "for i in range(len(test_eeg)):\n",
    "    test_eeg_tensor[i] = torch.from_numpy(test_eeg[i].copy())\n",
    "\n",
    "# Create one-hot label tensors\n",
    "train_label_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
    "test_label_tensor = torch.tensor(test_labels, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 1750 2 14\n"
     ]
    }
   ],
   "source": [
    "from braindecode.models import ATCNet, EEGNetv4\n",
    "from braindecode.util import set_random_seeds\n",
    "\n",
    "\n",
    "set_random_seeds(seed=42, cuda=False)\n",
    "\n",
    "n_channels = train_eeg_tensor.shape[1]\n",
    "n_times = train_eeg_tensor.shape[2]\n",
    "freq = 125\n",
    "input_window_sample = n_times // freq\n",
    "n_outputs = len(torch.unique(train_label_tensor))\n",
    "atc_model = ATCNet(\n",
    "    n_chans=n_channels, \n",
    "    n_outputs=n_outputs, \n",
    "    input_window_seconds=input_window_sample,  \n",
    "    sfreq=freq,\n",
    "    add_log_softmax=False\n",
    ").to(device)\n",
    "\n",
    "eeg_net = EEGNetv4(\n",
    "    n_chans=n_channels,\n",
    "    n_outputs=n_outputs,\n",
    "    n_times=n_times,\n",
    "    final_conv_length='auto'\n",
    ").to(device)\n",
    "\n",
    "print(f'n_channels:' {n_channels}, 'n_times:' {n_times}, 'n_outputs:' {n_outputs}, 'input_window_sample:'{input_window_sample})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([285, 16, 1750]) torch.Size([285])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/conv.py:454: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Convolution.cpp:1032.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7163\u001b[0m       \u001b[32m0.4737\u001b[0m        \u001b[35m0.6951\u001b[0m  3.8139\n",
      "      2        0.7231       \u001b[32m0.5263\u001b[0m        0.6955  3.3375\n",
      "      3        \u001b[36m0.6941\u001b[0m       0.5263        0.6977  3.1446\n",
      "      4        0.7013       0.5088        0.6967  3.3969\n",
      "      5        0.7311       0.5088        0.6965  3.5345\n",
      "      6        0.7227       0.5088        0.6955  3.4725\n",
      "      7        0.7065       0.4386        0.6961  3.5602\n",
      "      8        \u001b[36m0.6783\u001b[0m       0.4737        0.6986  3.3878\n",
      "      9        0.7270       0.4912        0.6979  3.2681\n",
      "     10        0.7240       0.5263        \u001b[35m0.6942\u001b[0m  3.3110\n",
      "     11        0.7138       0.5088        \u001b[35m0.6923\u001b[0m  3.5166\n",
      "     12        0.7102       0.4386        0.6923  3.4097\n",
      "     13        0.7196       0.4561        0.6924  3.3606\n",
      "     14        0.7218       0.4912        0.6978  3.5081\n",
      "     15        0.7179       0.5088        0.6971  3.3697\n",
      "     16        0.6872       0.5263        0.6991  3.5001\n",
      "     17        0.7012       0.5263        0.6987  3.3219\n",
      "     18        0.6917       0.4211        0.6955  3.4400\n",
      "     19        0.6817       0.4035        0.6961  3.4675\n",
      "     20        0.6811       0.3860        0.6969  3.7694\n",
      "     21        \u001b[36m0.6778\u001b[0m       0.3860        0.6977  3.4602\n",
      "     22        0.7013       0.4386        0.6996  3.5162\n",
      "     23        0.7133       0.5088        0.6994  3.5083\n",
      "     24        0.7089       0.4211        0.6962  3.3779\n",
      "     25        0.7386       0.5263        0.6961  3.4773\n",
      "     26        0.7099       \u001b[32m0.5439\u001b[0m        0.6984  3.4632\n",
      "     27        0.7084       0.4912        0.7005  3.3347\n",
      "     28        0.7004       0.4912        0.7033  3.2589\n",
      "     29        0.6867       0.5088        0.7072  3.3312\n",
      "     30        0.6797       0.5088        0.7087  3.3851\n",
      "     31        0.6899       0.5088        0.7106  3.3110\n",
      "     32        0.6856       0.5088        0.7081  3.5942\n",
      "     33        \u001b[36m0.6661\u001b[0m       \u001b[32m0.5789\u001b[0m        0.7063  3.4016\n",
      "     34        0.7111       0.5439        0.7059  3.4162\n",
      "     35        0.6710       0.5263        0.7088  3.4199\n",
      "     36        0.6774       0.5263        0.7119  3.5327\n",
      "     37        \u001b[36m0.6586\u001b[0m       0.5263        0.7168  3.2916\n",
      "     38        0.6981       0.5263        0.7219  3.3306\n",
      "     39        0.6686       0.5263        0.7226  3.5569\n"
     ]
    }
   ],
   "source": [
    "# using the Brain decode trainer API\n",
    "from braindecode.classifier import EEGClassifier\n",
    "\n",
    "# Define EEGClassifier with CrossEntropyLoss\n",
    "clf = EEGClassifier(\n",
    "    module=atc_model,\n",
    "    criterion=nn.CrossEntropyLoss,  # Works directly with raw logits\n",
    "    optimizer=optim.AdamW,  # Better optimizer for EEG data\n",
    "    lr=0.001,  # Learning rate\n",
    "    max_epochs=50,  # Train for sufficient epochs\n",
    "    batch_size=64,  # Optimal for EEG classification\n",
    "    iterator_train__shuffle=True,  # Ensure dataset shuffling\n",
    "    aggregate_predictions=False,  # Not using cropped mode\n",
    "    device=device  # Use GPU if available\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(train_eeg_tensor.shape, train_label_tensor.shape)\n",
    "clf.fit(train_eeg_tensor, train_label_tensor)\n",
    "\n",
    "clf.module_.eval()\n",
    "\n",
    "# Run inference on test data\n",
    "accuracy = clf.score(test_eeg_tensor, test_label_tensor)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39msave(atc_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124matc_net\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(atc_model, 'atc_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39msave(atc_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124matc_net\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(atc_model, 'atc_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]: Train Loss: 0.3700, Train Acc: 0.8125, Val Loss: 0.7693, Val Acc: 0.4375\n",
      "Epoch [2/100]: Train Loss: 0.2765, Train Acc: 0.9219, Val Loss: 0.7787, Val Acc: 0.5000\n",
      "Epoch [3/100]: Train Loss: 0.3104, Train Acc: 0.9062, Val Loss: 0.7954, Val Acc: 0.5000\n",
      "Epoch [4/100]: Train Loss: 0.2410, Train Acc: 0.9375, Val Loss: 0.8116, Val Acc: 0.5000\n",
      "Epoch [5/100]: Train Loss: 0.2250, Train Acc: 0.9375, Val Loss: 0.8208, Val Acc: 0.5000\n",
      "Epoch [6/100]: Train Loss: 0.2277, Train Acc: 0.9375, Val Loss: 0.8310, Val Acc: 0.5000\n",
      "Epoch [7/100]: Train Loss: 0.2151, Train Acc: 0.9531, Val Loss: 0.8401, Val Acc: 0.5000\n",
      "Epoch [8/100]: Train Loss: 0.2163, Train Acc: 0.9219, Val Loss: 0.8519, Val Acc: 0.5000\n",
      "Epoch [9/100]: Train Loss: 0.1886, Train Acc: 0.9844, Val Loss: 0.8632, Val Acc: 0.5000\n",
      "Epoch [10/100]: Train Loss: 0.1604, Train Acc: 0.9844, Val Loss: 0.8782, Val Acc: 0.5000\n",
      "Epoch [11/100]: Train Loss: 0.1087, Train Acc: 1.0000, Val Loss: 0.8963, Val Acc: 0.5000\n",
      "Early stopping at epoch 11\n"
     ]
    }
   ],
   "source": [
    "# Using a traditional pytorch training loop [still working on this]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "early_stopping_counter = 0\n",
    "patience = 25  # Stop training if no improvement in 10 epochs\n",
    "num_epochs = 100  # Maximum training epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # ðŸ”¹ Validation Loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct, val_total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == y_batch).sum().item()\n",
    "            val_total += y_batch.size(0)\n",
    "\n",
    "    val_loss /= val_total\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # ðŸ”¹ Early Stopping Check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stopping_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")  # Save best model\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "    if early_stopping_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w7/h3_3tsnj3nn2zhf_cfmn7nzc0000gn/T/ipykernel_75828/3078633745.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model.pth\"))\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# ðŸ”¹ Final Test Accuracy\n",
    "with torch.no_grad():\n",
    "    X_test_tensor, y_test_tensor = X_test_tensor.to(device), y_test_tensor.to(device)\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    test_acc = (predicted == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
    "\n",
    "print(f\"Final Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
